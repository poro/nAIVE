# nAIVE Engine PRD v4.0 — AI-Powered Networked Worlds

**Version:** 4.0
**Date:** February 14, 2026
**Author:** Mark Ollila
**Status:** Draft
**Classification:** Confidential

---

## 1. Executive Summary

nAIVE is an AI-native game engine where worlds are created by AI, state lives on a server, rendering happens on the client's GPU, control comes from anywhere — keyboard, browser, Telegram — and sharing requires nothing more than four memorable words.

The engine has been built from scratch in Rust across 16 phases, producing 16 working demos. The core stack is proven: wgpu deferred rendering, hecs ECS, SLANG shaders, Lua scripting, YAML data-driven scenes, Rapier physics, Kira audio, Gaussian splatting, MCP server integration, and a Telegram bot bridge prototype.

Previous PRDs defined the layers independently:
- **v1.0** specified the core engine (Phases 1-16, all complete)
- **v2.0** specified the intelligence layer (LLM NPCs, NL compiler, AI Director, Gen-3DGS, neural shaders)
- **v3.0** specified the network layer (server authority, four-word addresses, thin client, Telegram bridge)

**v4.0 is the unified product specification.** It integrates all three layers into a single coherent platform, resolves architectural decisions left open in prior versions, defines the rendering philosophy (why client-side, why not pixel streaming, when hybrid), formalizes the four-word addressing system, and establishes Snake Sweeper as the proof-of-concept first world.

The thesis: **the most interesting games of the next decade will not be authored — they will be grown, evolved, inhabited, and co-created by humans and AI working together in shared persistent worlds.**

---

## 2. Vision

```
"make it rain in black.squirrel.white.deer"
```

A message sent from Telegram. Within one second, every player connected to that world sees rain particles falling, hears rain audio, and watches the lighting shift. The AI parsed "make it rain" into a weather system call. The server executed it in the world's Lua environment. State deltas flowed to all connected clients. The world changed because someone asked it to — from a chat app, without touching a game controller.

### 2.1 What Makes This Different

| Traditional Engine | nAIVE v4.0 |
|---|---|
| Games are compiled binaries | Worlds are YAML + Lua, generated by AI |
| Distribution via app stores | Share a 4-word address: `snake.3d.nokia.mark` |
| Authoring requires programming | Describe what you want in natural language |
| Static content after shipping | AI Director evolves the world while players play |
| NPCs follow behavior trees | NPCs are LLM agents with persistent memory |
| Single-player or dedicated servers | Any world is multiplayer by default |
| Control via gamepad/keyboard only | Also controllable via Telegram, CLI, MCP, browser |
| Server renders pixels or clients run full logic | Server holds state, clients render — clean split |
| Shaders are HLSL/GLSL platform-locked | SLANG shaders cross-compile to any GPU backend |
| 3D assets from art pipelines only | Gaussian splats generated from text prompts (Gen-3DGS) |
| Render pipeline hardcoded in C++ | YAML-defined render pipeline DAG — add passes without recompiling |
| Fixed visual style per game | Neural render passes swap visual styles at runtime (Ghibli → pixel art → photorealistic) |

### 2.2 The Three Promises

**For creators:** Describe what you imagine. AI builds it. Test it locally. Publish it with a four-word name. Anyone in the world can play it instantly — in a browser, no download.

**For players:** Hear about a game. Type four words. You're in. No download, no account, no app store. Your friend is already there. Someone on Telegram just made it rain.

**For AI:** You're not a tool — you're a collaborator, an inhabitant, a director. You live inside the world. You remember. You adapt. You create alongside humans in real-time.

### 2.3 Design Philosophy

Six founding principles, established in the v1.0 PRD, remain the philosophical bedrock of v4.0:

**The AI agent IS the editor.** Unlike Unity and Unreal, which invest 80% of their engineering in graphical editors, nAIVE has no visual editor. The AI agent — Claude Code, or any MCP-capable LLM — is the editor. This is not a limitation; it's a bet. With modern coding agents, AI asset generators, and AI vision models, the entire game development workflow can happen through text files, CLI commands, and pipes. The graphical editor is dead weight. This thesis was validated at a Supercell AI Hackathon where a complete game was built using Claude Code as the sole development interface.

**Everything is a file.** Scenes, entities, materials, render pipelines, input bindings, event schemas — all human-readable YAML files that an AI agent can read, understand, diff, and modify. No proprietary binary formats. No opaque editor state. Every aspect of a world is inspectable, version-controllable, and AI-editable.

**Unix pipes connect everything.** AI services are accessed via standardized CLI pipes — tools that read from stdin and write to stdout or files:
- **Meshy** for AI-generated 3D geometry (text → mesh/splat)
- **ElevenLabs** for AI-generated voice and audio (text → speech)
- **Flux / Stable Diffusion** for AI-generated textures (text → image)
- **Claude API** for scene generation, NPC dialogue, world commands (text → YAML/Lua)

These external services are first-class rendering primitives. A world creator doesn't need to be an artist — they describe what they want, and the AI pipeline generates it. The engine's YAML-based format means generated assets slot into scenes without any manual integration.

**SLANG shaders from day one.** NVIDIA's SLANG shading language compiles to Metal (macOS), SPIR-V (Vulkan), WGSL (WebGPU), and CUDA. It supports automatic differentiation for neural rendering, modules for composable shader code, and a reflection API that auto-generates GPU resource bindings. SLANG is the bridge between today's handcoded shaders and tomorrow's learned neural shaders — the same language, the same pipeline YAML, the same toolchain.

**Gaussian Splatting as first-class primitive.** 3D Gaussian Splats are not a plugin. They are a native renderable type alongside traditional meshes, with hybrid depth compositing built into the deferred render pipeline. Splats receive the same PBR lighting, cast the same shadows, and coexist in the same ECS world as mesh entities. This decision is forward-looking: as AI-generated 3D content increasingly uses splat representations (via Gen-3DGS, NeRF-to-splat conversion, photogrammetry), the engine is ready to render it natively.

**AI observability built in.** The engine can stream frames for AI vision analysis, expose game state via a command socket, log all events for AI consumption, and accept simulated input for automated playtesting. Every system emits structured data that an AI agent can observe, reason about, and act upon. This isn't an afterthought — it's a core architectural requirement. The MCP server, event bus, and headless mode all exist to make the engine legible to AI.

### 2.4 The Future of Rendering

nAIVE is built on a conviction about where real-time rendering is going. This section describes that trajectory and how every technical decision in the engine aligns with it.

#### The Rendering Revolution

Real-time 3D rendering has followed a clear arc:

```
1990s  Fixed-function pipeline     Hardwired vertex/pixel ops, no shaders
2000s  Programmable shaders        HLSL/GLSL — artists write lighting math by hand
2010s  Physically-based rendering  Cook-Torrance, metallic/roughness, HDR, IBL
2020s  Neural rendering begins     NeRF, 3D Gaussian splatting, differentiable rendering
2025+  AI-native rendering         Learned shaders, generated assets, prompted visual style
```

Most engines are stuck at PBR (2010s). They added ray tracing as an incremental upgrade to the same paradigm — rays instead of rasters, but still handcoded shaders, still artist-modeled geometry, still static visual styles.

**nAIVE skips ahead.** It implements PBR as a foundation (Cook-Torrance GGX, shadow mapping, bloom, FXAA — all working today), but the architecture is designed for the next three leaps:

#### Leap 1: Gaussian Splats Replace Polygons for AI-Generated Content

Traditional 3D content requires: concept art → modeling (Maya/Blender) → UV unwrapping → texturing → rigging → export. This takes days to months per asset.

Gaussian splat content requires: text prompt → Gen-3DGS → .ply file → scene entity. This takes seconds to minutes.

The geometric representation of 3D content is shifting from polygonal meshes (optimized for human artists using modeling tools) to Gaussian splats (optimized for AI generation from images and text). nAIVE renders both natively because the transition won't be instant — mesh and splat content will coexist for years. But the direction is clear: **AI-generated 3D content will be the norm, not the exception, within five years.**

nAIVE's Gaussian splatting renderer is already integrated into the deferred pipeline. Generated splats receive the same PBR lighting as handcrafted meshes. When Gen-3DGS is implemented, the path from imagination to rendered 3D object is:

```
"a crystal dragon perched on obsidian rocks"
  → CLIP text encoding
  → Multi-view diffusion (Zero123++ / MVDream)
  → 3DGS reconstruction
  → Differentiable splat optimization
  → LOD generation
  → .ply asset → scene entity → rendered with PBR shadows and bloom
```

No artist. No modeling tool. No UV unwrapping. No texture painting.

#### Leap 2: Neural Shaders Replace Handcoded Shaders

Today's render pipeline has handcoded SLANG passes: geometry, lighting, bloom, tone mapping, FXAA. Each stage implements a specific mathematical function written by a programmer.

Tomorrow's render pipeline has **learned** passes: a neural network trained to produce the visual output, using gradient descent instead of hand-tuned math. SLANG's built-in auto-differentiation makes this transition smooth — a traditional shader stage and a neural shader stage live in the same YAML pipeline definition, consume the same texture inputs, produce the same texture outputs.

Use cases already proven in research:
- **Style transfer:** Learn "Studio Ghibli watercolor" or "pixel art" or "dark souls gothic" as a post-processing pass. Change the entire visual style of a world by swapping one weight file — no asset changes, no shader rewrites.
- **Super-resolution:** Render at half resolution, upscale with a learned neural pass. 2x performance for free.
- **Ambient occlusion:** Replace screen-space AO (SSAO) with a neural estimator trained on path-traced ground truth. Better quality, similar cost.
- **Denoising:** Real-time denoising of noisy ray-traced frames using learned temporal filtering.

The revolutionary implication: **visual style becomes data, not code.** A world's aesthetic is a weight file, downloadable, swappable, sharable. "I like how that game looks" → download its style weights → apply to your world. Visual styles become a marketplace, not a months-long art direction effort.

```yaml
# Swap visual style by changing one line
passes:
  - name: style_transfer
    type: neural
    weights: assets/neural/ghibli.weights      # ← change this line
    # weights: assets/neural/pixel_art.weights  # or this
    # weights: assets/neural/noir.weights       # or this
    inputs: [bloomed_color, depth]
    output: styled_color
```

#### Leap 3: Prompt-to-Render — The Endgame

The logical conclusion of AI-native rendering:

```
"A moonlit forest with fireflies, Studio Ghibli style, gentle fog"
```

This single sentence contains everything needed to render a scene:
- **Geometry:** "forest" → Gen-3DGS produces tree splats, ground plane mesh
- **Lighting:** "moonlit" → directional light (blue-white, low angle), point lights for fireflies
- **Particles:** "fireflies" → spawned emissive particle entities with random float behavior
- **Atmosphere:** "gentle fog" → volumetric fog pass in the render pipeline
- **Style:** "Studio Ghibli" → neural style transfer weights loaded as a render pass
- **Audio:** "forest" context → ambient cricket/owl audio generated via AI

The engine doesn't need an artist. It doesn't need a programmer. It needs a **vision** — expressed in natural language — and AI systems that can compile that vision into the engine's existing YAML + Lua + SLANG format.

This is not science fiction. Every component exists today in some form:
- Gen-3DGS (text → splats) is demonstrated in research papers (DreamGaussian, GaussianDreamer)
- Neural style transfer runs in real-time on consumer GPUs (Neural Style Transfer, AdaIN)
- Text-to-scene generation works (Claude generating nAIVE YAML scenes today)
- Text-to-audio is production-ready (ElevenLabs, Bark, MusicGen)
- Text-to-texture is production-ready (Flux, Stable Diffusion)

nAIVE's contribution is the **integration architecture** — the YAML pipeline DAG, the SLANG differentiable shader toolchain, the first-class splat renderer, the MCP server for AI control, the event bus for AI observability — that makes all of these components composable into a single runtime.

#### The AI Observability Loop

Rendering is not just output — it's also input for AI:

```
Engine renders frame
  → Frame streamed via command socket to AI vision model
  → AI analyzes: "the lighting is too flat, the fog is obscuring the path"
  → AI modifies render pipeline YAML: increase directional light intensity, reduce fog density
  → Engine hot-reloads pipeline
  → Next frame looks better
  → AI observes improvement, records the adjustment

This is a closed-loop rendering system where AI both generates and evaluates visuals.
```

The MCP server already supports `naive/render/pipeline` for querying and modifying the render pipeline. Combined with frame streaming (via the command socket) and the event bus, the engine is fully observable by AI. An Art Director agent can watch the game run, evaluate visual quality, and make real-time adjustments — the same feedback loop a human art director uses, but automated and continuous.

#### Why This Matters

Every other engine treats rendering as a solved problem — implement PBR, add ray tracing, ship. The renderer is static infrastructure, not a creative surface.

nAIVE treats rendering as the **primary creative interface between AI and the visual world.** The render pipeline is data (YAML), shaders are differentiable (SLANG), geometry is AI-generated (Gaussian splats), visual style is learned (neural passes), and the entire system is observable and controllable by AI agents (MCP + event bus + frame streaming).

This is not an incremental improvement to game engine rendering. It is a fundamentally different relationship between intelligence and visual output. The question nAIVE answers is not "how do we render faster?" but **"what happens when AI can see, understand, and modify the rendering pipeline itself?"**

---

## 3. Core Technical Differentiators

nAIVE is not a Unity clone written in Rust. It makes six fundamental bets that no existing engine makes simultaneously.

### 3.1 SLANG as Shader Language

nAIVE uses [SLANG](https://shader-slang.com/) — NVIDIA's modern shader language — instead of raw HLSL, GLSL, or WGSL.

**Why SLANG matters:**

| Feature | SLANG | Raw WGSL/HLSL/GLSL |
|---------|-------|---------------------|
| Cross-compilation | Single source → WGSL, SPIR-V, HLSL, Metal, GLSL | Write per-platform |
| Module system | `import` with namespaces, interfaces, generics | Copy-paste or #include hacks |
| Differentiable | Built-in auto-differentiation for neural shader training | Not possible |
| Type safety | Generics, interfaces, associated types | Weak typing |
| IDE support | Language server, error messages with context | Minimal |

**How it's used today:** All render passes (geometry, deferred lighting, bloom, tonemap, FXAA, shadow mapping) are SLANG source files in `project/shaders/passes/`. They cross-compile to WGSL at load time for wgpu, with no manual shader translation needed.

**Why it's revolutionary for v4.0:** SLANG's built-in differentiability is the foundation for neural render passes. A traditional shader stage can be gradually replaced with a learned neural equivalent — trained using SLANG's auto-diff, deployed as a compute shader, all within the same pipeline YAML. No other engine has this path from handcoded → learned shaders in a single language.

```slang
// Traditional SLANG pass
[shader("fragment")]
float4 tonemap(float4 hdr_color) {
    return float4(hdr_color.rgb / (hdr_color.rgb + 1.0), 1.0);
}

// Neural SLANG pass (same language, learned weights)
[Differentiable]
float4 neural_tonemap(float4 hdr_color, TensorView<float> weights) {
    // Forward pass through learned network
    float4 hidden = relu(matmul(weights[0], hdr_color));
    return sigmoid(matmul(weights[1], hidden));
}
```

### 3.2 Gaussian Splatting as First-Class Rendering Primitive

Most engines treat Gaussian splatting as a plugin or post-process effect. In nAIVE, **Gaussian splats are a core rendering primitive alongside meshes** — they flow through the same deferred pipeline, receive the same lighting, cast the same shadows.

**What this means technically:**
- `.ply` Gaussian splat files load with the same API as `.gltf` mesh files
- Splats render in the G-Buffer pass, writing to the same albedo/normal/depth targets as mesh geometry
- Deferred lighting (Cook-Torrance GGX, shadow mapping, bloom) applies identically to splat and mesh surfaces
- A scene can mix mesh entities and splat entities freely — they coexist in the same ECS world

**Why this matters for v4.0:**
- **Gen-3DGS** (text → Gaussian splats) produces assets that plug directly into scenes with zero format conversion
- Players in a networked world can see AI-generated splat objects alongside hand-modeled mesh objects with consistent lighting
- The path from "imagine a crystal dragon" to "crystal dragon rendered with PBR shadows and bloom" is: text → Gen-3DGS → .ply → scene entity. No art pipeline.

```yaml
# Mesh and splat entities coexist in the same scene
entities:
  - id: castle
    components:
      mesh_renderer:
        mesh: assets/meshes/castle.gltf           # traditional mesh
        material: assets/materials/stone.yaml

  - id: dragon
    components:
      splat_renderer:
        splat: assets/splats/crystal_dragon.ply    # AI-generated splat
        scale: 2.0
```

### 3.3 Data-Driven YAML Render Pipeline

The render pipeline is not hardcoded in Rust. It's a **YAML-defined directed acyclic graph (DAG) of passes** — you can add, remove, or reorder render stages without recompiling.

```yaml
# project/shaders/render_pipeline.yaml
passes:
  - name: shadow_pass
    type: raster
    shader: passes/shadow.slang
    output: shadow_map

  - name: geometry_pass
    type: raster
    shader: passes/geometry.slang
    outputs: [albedo, normal, depth, metallic_roughness]

  - name: splat_pass
    type: compute
    shader: passes/splat_render.slang
    inputs: [depth]
    outputs: [albedo, normal]         # writes to same G-Buffer

  - name: lighting_pass
    type: raster
    shader: passes/deferred_light.slang
    inputs: [albedo, normal, depth, metallic_roughness, shadow_map]
    output: hdr_color

  - name: bloom_pass
    type: raster
    shader: passes/bloom.slang
    inputs: [hdr_color]
    output: bloomed_color

  - name: style_transfer                    # v4.0: Neural pass
    type: neural
    weights: assets/neural/ghibli.weights
    inputs: [bloomed_color, depth]
    output: styled_color

  - name: tonemap_pass
    type: raster
    shader: passes/tonemap.slang
    inputs: [styled_color]
    output: ldr_color

  - name: fxaa_pass
    type: raster
    shader: passes/fxaa.slang
    inputs: [ldr_color]
    output: final_color
```

**Why this matters:**
- A world creator can customize the render pipeline per-world (this world uses cel-shading, that world uses photorealistic)
- Neural passes slot in alongside traditional passes — same YAML, same DAG, same texture flow
- Hot-reloading the pipeline YAML changes the visual style without restarting the engine
- AI agents (Art Director) can modify the pipeline at runtime: "switch to pixel art style" → swap the style_transfer weights

### 3.4 AI as Runtime Primitive

The v2.0 PRD's central thesis: **"What if the AI IS the game?"**

In traditional engines, AI is a development tool (Copilot generates code, then you ship). In nAIVE, AI is a **runtime component** that runs alongside physics and rendering:

| Traditional | nAIVE v4.0 |
|------------|-----------|
| AI writes code at dev time | AI runs inside the game at play time |
| NPCs follow pre-authored scripts | NPCs are LLM agents that reason, remember, and adapt |
| Game balance is tuned by humans pre-launch | AI Director tunes balance in real-time based on player telemetry |
| 3D assets created by artists | 3D assets generated from text descriptions on demand |
| Visual style fixed at compile time | Neural render passes swap styles at runtime |
| Level design is manual | NL Compiler generates levels from natural language descriptions |

This is the deepest bet nAIVE makes. Every other engine treats AI as external tooling. nAIVE treats AI as an internal system — as fundamental as the renderer or the physics engine.

### 3.5 Self-Modifying Engine (Plugin Architecture)

nAIVE is designed to modify itself at runtime. The plugin system allows:

```rust
// Plugin trait — hot-loadable .dylib/.so modules
pub trait NaivePlugin: Send + Sync {
    fn name(&self) -> &str;
    fn version(&self) -> (u32, u32, u32);
    fn on_load(&mut self, ctx: &mut PluginContext);
    fn on_update(&mut self, ctx: &mut PluginContext, dt: f32);
    fn on_unload(&mut self, ctx: &mut PluginContext);
}
```

**Capabilities:**
- **Dynamic loading** via `libloading`: load/unload .dylib at runtime without restart
- **ABI boundary** with versioned manifest: plugins declare compatibility, engine validates
- **Hot-swap**: replace a plugin while the world is running (e.g., swap physics solver, swap AI model)
- **AI-driven**: the AI Director can load/unload plugins to change game genre mid-session (with player opt-in)

**Use cases:**
- Weather system plugin: loaded when "make it rain" is commanded, unloaded when weather clears
- Genre transformation: load a combat plugin to turn a peaceful world into an arena
- Custom physics: swap Rapier for a cloth simulation plugin for a specific world

### 3.6 Extended MCP Server (AI ↔ Engine Interface)

The v1.0 MCP server is extended with tools for every v4.0 capability:

| MCP Tool | Purpose |
|----------|---------|
| `naive/scene/load` | Load a scene YAML into the engine |
| `naive/scene/query` | Query entities, components, transforms |
| `naive/scene/modify` | Add/remove/update entities and components |
| `naive/nl/compile` | Natural language → YAML + Lua scene generation |
| `naive/agent/create` | Spawn an LLM NPC with personality profile |
| `naive/agent/converse` | Talk to an NPC agent (test dialogue) |
| `naive/director/status` | Query AI Director's current analysis and planned interventions |
| `naive/director/intervene` | Manually trigger a Director intervention |
| `naive/generate/splat` | Generate a Gaussian splat from text description (Gen-3DGS) |
| `naive/plugin/list` | List loaded plugins and their status |
| `naive/plugin/swap` | Hot-swap a plugin at runtime |
| `naive/render/pipeline` | Query or modify the render pipeline YAML |
| `naive/world/publish` | Publish current scene to world server with four-word name |
| `naive/world/status` | Query connected clients, tick rate, entity count |

This makes Claude Code (or any MCP client) a first-class citizen of the engine — it can create worlds, spawn NPCs, modify gameplay, generate assets, and manage the render pipeline through the same protocol.

---

## 4. Architectural Decisions

This section documents the core architectural choices and their rationale. These decisions shape everything that follows.

### 4.1 Rendering Philosophy: Client-Side Rendering, Server-Side State

**Decision:** The server holds canonical world state and runs all game logic. Clients render locally using their own GPU. The server never touches a pixel.

**This is the single most important architectural decision in nAIVE v4.0.**

#### Options Evaluated

**Option A: Server-Side Rendering (Pixel Streaming)**

The server renders frames and streams compressed video to clients (the GeForce NOW / Xbox Cloud Gaming model).

| Dimension | Assessment |
|-----------|-----------|
| Server GPU cost | Catastrophic. One GPU per concurrent client session. A single NVIDIA A10G ($1/hr) serves ~4 concurrent 1080p streams. 100 concurrent players = $25/hr = $18,000/month. |
| Latency | 30-100ms added (encode + network + decode) on top of game logic. Unacceptable for action games. |
| Bandwidth | 5-20 Mbps per client (video stream). A 4-player Snake Sweeper session uses 20-80 Mbps server egress. |
| Client requirements | Minimal (video decoder only). Works on any device with a screen. |
| Scaling | Linear cost per client. Hosting 1,000 worlds with 10 players each requires 10,000 GPU sessions. |

**Verdict: Rejected.** Destroys the "anyone can host worlds on a $5 VPS" vision. The cost structure makes it impossible to run hundreds of concurrent worlds affordably. It works for AAA cloud gaming services backed by billion-dollar infrastructure — not for an indie platform.

**Option B: Client-Side Rendering with Server Authority (Chosen)**

The server runs ECS + physics + Lua game logic headlessly (no GPU). It streams state deltas (~500 bytes/tick) over WebSocket. Clients download the scene definition once, then render locally using their own GPU.

| Dimension | Assessment |
|-----------|-----------|
| Server GPU cost | Zero. Server is CPU-only. A $5/month VPS runs ~100 worlds. |
| Latency | Sub-10ms input-to-local-render. State deltas arrive within 50-100ms but client renders at local frame rate. |
| Bandwidth | ~10 KB/s per client (state deltas). A 4-player session uses ~40 KB/s total server egress. |
| Client requirements | Any GPU from Intel integrated to RTX 4090. WebGPU in browsers. |
| Scaling | Sublinear cost. Adding clients to an existing world costs only delta bandwidth. |

**Verdict: Chosen.** This is what Minecraft, Roblox, Fortnite, and every successful multiplayer game uses. State is tiny; pixels are expensive. A Snake Sweeper world has ~50 entities. The state delta is ~500 bytes per tick. Rendering one frame at 1080p is 6,220,800 bytes. Server rendering would cost **12,000x more bandwidth** per frame, plus GPU hardware.

**Option C: Hybrid (Adaptive Fallback)**

Default to client-side rendering (Option B). For extremely low-end devices (old phones, Chromebooks without WebGPU), optionally fall back to server-side rendering at reduced resolution.

| Dimension | Assessment |
|-----------|-----------|
| Complexity | High. Requires maintaining both rendering paths and a server GPU pool. |
| Use case | Accessibility for lowest-tier devices. |
| Priority | Low. WebGPU covers modern browsers; native client covers desktops. |

**Verdict: Deferred.** Nice-to-have for accessibility, but not part of the core architecture. Can be added later as an optional service tier without changing the fundamental design.

#### The Cost Equation

```
Server-side rendering (Option A):
  100 worlds x 10 players x $0.25/hr GPU = $250/hr = $180,000/month

Client-side rendering (Option B):
  100 worlds on 2-core VPS = $20/month
  Bandwidth: 100 worlds x 10 players x 10 KB/s = 10 MB/s = ~$5/month

Ratio: 9,000:1 cost advantage for client-side rendering
```

This isn't a close call. Client-side rendering is the only architecture that allows nAIVE to scale to thousands of worlds without venture capital funding the GPU bill.

### 4.2 Why Four Words

**Decision:** Every world gets a human-memorable address composed of exactly four words from a curated dictionary.

#### The Memorability Problem

URLs are the internet's addressing system, but they fail for games:
- `https://naive.world/a1b2c3d4-5678-9012-3456-789abcdef012` — nobody remembers this
- `https://naive.world/games/mark/snake-v3-final-FINAL2` — ugly, not shareable verbally
- `black.squirrel.white.deer` — you can tell someone this across the room, in a tweet, on a phone call

**Memorability is the product feature.** The address IS the sharing mechanism. If you can't remember it after hearing it once, you've lost 90% of potential players. The viral loop depends entirely on "hey, connect to [four words]."

#### The Math

A curated dictionary of ~2,000 common English words provides:

| Words | Unique Addresses | Sufficient For |
|-------|-----------------|----------------|
| 2 words | 4 million | Small hobby project |
| 3 words | 8 billion | Earth's population, once each |
| **4 words** | **16 trillion** | Every person on Earth publishing 2,000 worlds each |

16 trillion addresses is absurdly more than needed. If nAIVE becomes the most successful platform in history with 1 billion users each publishing 100 worlds, that's 100 billion worlds — 0.6% of the address space.

**Why not 3 words?** 8 billion is numerically sufficient today but creates collision pressure as the platform grows. Four words provide 2,000x more headroom for the same dictionary size, essentially eliminating namespace exhaustion as a concern forever.

**Why not 5+ words?** Diminishing returns on address space (already 16 trillion with 4) and declining memorability. Four words is the sweet spot: short enough to say in one breath, long enough to be unique.

#### Prior Art

- **what3words** uses 3 words from a 40,000-word dictionary to address every 3m x 3m square on Earth (~57 trillion combinations). Proven that word-based addressing works for consumer products.
- **Diceware passphrases** demonstrate that 4-6 random words are memorizable by average users.
- **Pokemon naming** (two-part compound names) and **Xbox gamertags** show that word-based identifiers become part of identity and culture.

#### Dictionary Curation Rules

The ~2,000 word dictionary must be:

1. **Common nouns and adjectives only** — `tiger`, `crystal`, `storm`, `golden`, `silver`, `deep`
2. **Visually evocable** — words that create mental images, not abstractions (`however`, `despite`, `whereas` are excluded)
3. **No offensive words** — no slurs, profanity, or words with strongly negative connotations in major cultures
4. **Unambiguous spelling** — no homophones that cause confusion (`there`/`their`/`they're`)
5. **Easy to pronounce** across English accents — no tongue-twisters, no silent letters
6. **Single syllable or two syllables preferred** — keeps addresses short when spoken aloud
7. **No proper nouns** — no brand names, no place names, no person names

Example good words: `black`, `tiger`, `storm`, `crystal`, `river`, `golden`, `swift`, `silent`, `iron`, `amber`

Example bad words: `although`, `nevertheless`, `miscellaneous`, `rhythm`, `queue`

### 4.3 Server Authority Over Client Authority

**Decision:** The server is the single source of truth for all world state.

**Why:**
- **Anti-cheat by design.** Clients can only send input events (key presses). They cannot claim "my snake is at position X" or "my score is Y." The server computes all state.
- **Consistent for all viewers.** Every connected client sees the exact same world. No desync, no "it looks different on my screen."
- **External control works naturally.** Telegram commands, MCP tools, and AI Director interventions all work because the server just executes them in the Lua environment. If the client held authority, external commands would require complex reconciliation.
- **Multiplayer is free.** Adding a second player to a server-authoritative world is trivial — spawn another entity, process another input stream. No peer-to-peer networking, no host migration, no NAT traversal.

### 4.4 WebSocket Over UDP

**Decision:** Client-server communication uses WebSocket (TCP-based), not UDP.

**Why:**
- **Tick rate is 10-30 Hz**, not 60-120 Hz. Snake Sweeper moves at 0.28s per tile. State updates at 20 Hz is more than sufficient. The latency budget is generous.
- **WebSocket works everywhere** — through firewalls, proxies, NAT, and in browsers natively. UDP requires STUN/TURN servers, NAT hole-punching, and cannot work in browser contexts without WebRTC (which adds massive complexity).
- **Reliability matters more than speed.** A missed spawn event or despawn event corrupts client state. TCP guarantees delivery order. With UDP, we'd need to build our own reliability layer on top.
- **Bandwidth is tiny.** At ~500 bytes per tick, we're nowhere near TCP overhead being a bottleneck.

**When to reconsider:** If nAIVE needs to support fast-paced FPS or racing games at 60+ Hz tick rates, WebRTC DataChannels (unreliable mode) would be appropriate. This is a v5.0 concern.

### 4.5 Lua on Server Only

**Decision:** Game logic scripts (Lua) run exclusively on the server. Clients never execute game logic.

**Why:**
- **Clients are dumb renderers.** They receive "entity X is at position Y" and render it. They don't need to know why.
- **Single execution path** prevents divergence. If both server and client ran Lua, they could produce different results from the same inputs (floating point, timing, random seeds).
- **Security.** Lua scripts have access to entity spawning, physics, scoring. Running untrusted Lua on the client is a security risk. The server is trusted.
- **Simplicity.** The client codebase is dramatically simpler without a script runtime.

### 4.6 Scene YAML as World Format

**Decision:** A "world" is just a directory of files: YAML scenes, Lua scripts, YAML materials, glTF meshes, audio files.

**Why:**
- **Already exists.** The v1.0 engine loads this format today.
- **Human-readable.** A scene file is inspectable, editable, diffable.
- **AI-generatable.** Claude Code already knows the nAIVE format. Natural language → YAML is a well-understood problem.
- **Version-controllable.** Git can track world changes, enable forking, enable rollback.
- **No proprietary binary format.** Worlds are portable, hackable, shareable as zip files.

---

## 5. Architecture

### 5.1 Three-Layer Stack

```
                    ┌─────────────────────────────────────────────┐
                    │              CREATOR LAYER                   │
                    │                                              │
                    │  Claude Code ──────> YAML + Lua + Assets     │
                    │  NL Compiler ──────> Scene Generation        │
                    │  Telegram ─────────> Live World Commands     │
                    │  MCP Server ──────> Agent Interaction        │
                    │  Multi-Agent Swarm > Collaborative Building  │
                    └──────────────────┬──────────────────────────┘
                                       │ publish / command
                    ┌──────────────────▼──────────────────────────┐
                    │              SERVER LAYER                     │
                    │                                              │
                    │  World Registry (4-word names ↔ world IDs)  │
                    │  Per-World:                                  │
                    │    ├── hecs ECS    (canonical state)         │
                    │    ├── Rapier      (headless physics)        │
                    │    ├── mlua        (game logic scripts)      │
                    │    ├── AI Agents   (LLM NPC runtime)        │
                    │    ├── AI Director (adaptive evolution)      │
                    │    └── Broadcaster (delta → WebSocket)       │
                    │  WebSocket Server (tokio + tungstenite)      │
                    │  Telegram Bridge  (teloxide)                 │
                    │  Asset CDN        (scene + mesh + audio)     │
                    └──────────────────┬──────────────────────────┘
                                       │ state deltas (WebSocket, ~10 KB/s)
                    ┌──────────────────▼──────────────────────────┐
                    │              CLIENT LAYER                     │
                    │                                              │
                    │  State Applicator (delta → local ECS)        │
                    │  wgpu Renderer    (local GPU, deferred PBR)  │
                    │  Kira Audio       (local speakers)           │
                    │  Input Capture    (keyboard/mouse → server)  │
                    │  UI Overlay       (HUD, menus, text)         │
                    │                                              │
                    │  Targets:                                    │
                    │    Native  — macOS / Windows / Linux          │
                    │    Browser — WebGPU + WASM (zero install)    │
                    └─────────────────────────────────────────────┘
```

### 5.2 Data Flow

```
Player presses "W"
  → Client sends: {"input": "key_down", "key": "W", "player": "p1"}
  → Server receives input event
  → Server tick: Lua script processes input, moves snake entity
  → Server computes new positions, collision, scoring
  → Server produces delta: {"entity": "snake_head", "transform": {"position": [3,0,5]}}
  → Delta broadcast to ALL connected clients via WebSocket
  → Each client applies delta to local ECS
  → Each client renders updated scene at local frame rate (60+ FPS)
  → Total round-trip: 50-150ms (imperceptible for Snake Sweeper's 280ms tick)
```

### 5.3 Headless Server Binary

`naive-server` — the same ECS + physics + scripting engine, compiled without wgpu:

```
naive-server
  ├── World Manager          (runs N worlds concurrently via tokio)
  ├── WebSocket Server       (accepts client connections)
  ├── Telegram Bridge        (receives NL commands via teloxide)
  ├── World Registry         (four-word name → world ID, backed by SQLite)
  ├── Asset Store            (serves scene + asset files, optional CDN)
  ├── AI Agent Runtime       (LLM NPC inference, tiered)
  ├── AI Director            (per-world adaptive system)
  └── Per-World Instance:
      ├── hecs World         (canonical ECS state)
      ├── Rapier Physics     (headless simulation, no rendering)
      ├── mlua ScriptRuntime (Lua game logic, all scripts)
      ├── EventBus           (typed pub/sub for internal events)
      └── State Broadcaster  (dirty-flag tracking, delta serialization, WebSocket fan-out)
```

**Key implementation detail:** The existing `--headless` flag already runs the engine without a window. The server binary is a feature-flagged build that excludes `src/renderer.rs`, `src/pipeline.rs`, `src/ui.rs`, `src/font.rs`, and all wgpu/winit/kira dependencies.

```toml
# Cargo.toml
[features]
default = ["client"]
client = ["dep:wgpu", "dep:winit", "dep:kira"]
server = ["dep:tokio", "dep:tungstenite", "dep:teloxide"]

[[bin]]
name = "naive-runtime"      # current: full local engine (dev + singleplayer)
required-features = ["client"]

[[bin]]
name = "naive-server"       # headless world server
required-features = ["server"]

[[bin]]
name = "naive-client"       # thin rendering client
required-features = ["client"]
```

Shared library: `src/lib.rs` exports ECS, physics, scripting, scene loading, event bus, component definitions. All three binaries compose from this shared core.

### 5.4 Thin Client Binary

`naive-client` — rendering + input + audio, no game logic:

```
naive-client connect black.squirrel.white.deer
  ├── World Resolver         (4-word name → server address via registry API)
  ├── WebSocket Client       (receives state deltas)
  ├── Asset Cache            (downloads + caches scene assets locally)
  ├── State Applicator       (applies deltas to local ECS for rendering)
  ├── wgpu Renderer          (local GPU, full deferred pipeline)
  ├── Kira Audio             (local audio playback, triggered by server events)
  ├── Input Capture          (keyboard/mouse → sends to server as events)
  └── UI Overlay             (HUD rendered from server-sent UI commands)
```

### 5.5 Connection Lifecycle

```
1. Client resolves four-word name → server address + world ID
      GET https://registry.naive.world/resolve/black.squirrel.white.deer
      → { "server": "wss://us-east.naive.world", "world_id": "a1b2c3d4", "name": "..." }

2. WebSocket handshake with world server
      wss://us-east.naive.world/worlds/a1b2c3d4

3. Server sends: full scene snapshot
      { "scene": "scenes/snake.yaml", "assets": ["meshes/cube.gltf", ...], "state": {...} }

4. Client downloads assets it doesn't have (from CDN or server)
      Cached locally for fast reconnect (~/.naive/cache/)

5. Client builds local ECS + renderer from scene definition
      Same scene loader as naive-runtime, minus Lua scripts

6. Server streams state deltas every tick (10-30 Hz)
      Binary-encoded, delta-compressed

7. Client applies deltas to local ECS, renders at local frame rate
      State application is lock-free: deltas queued, applied before each render

8. Client sends input events to server
      {"input": "key_down", "key": "W", "player": "p1", "tick": 1042}

9. On disconnect: client state is discarded (server is truth)
      Reconnect replays from fresh snapshot
```

### 5.6 State Delta Protocol

```json
{
  "tick": 1042,
  "updates": [
    {
      "entity": "snake_head",
      "transform": {"position": [3, 0, 5], "rotation": [0, 90, 0]}
    },
    {
      "entity": "snake_seg_4",
      "transform": {"position": [2, 0, 5]}
    },
    {
      "spawn": {
        "id": "food_7",
        "mesh": "procedural:sphere",
        "material": "assets/materials/food_gold.yaml",
        "position": [8, 0, 2],
        "scale": [0.3, 0.3, 0.3]
      }
    },
    {"despawn": "food_3"},
    {"component": {"entity": "player_1", "hidden": false}},
    {
      "ui": [
        {"type": "text", "x": 10, "y": 10, "text": "Score: 450", "size": 24, "color": [1,1,1,1]},
        {"type": "rect", "x": 0, "y": 0, "w": 800, "h": 40, "color": [0,0,0,0.8]}
      ]
    },
    {
      "audio": {"type": "play_sfx", "id": "eat_7", "file": "assets/audio/eat.mp3", "vol": 0.8}
    }
  ]
}
```

**Optimization:** Only changed components are sent. Position deltas can use quantized 16-bit fixed-point (0.01 unit precision = ±327 meters range) for bandwidth-critical scenarios.

**Bandwidth analysis:**

| Scenario | Active Entities | Delta Size/Tick | At 20 Hz |
|----------|----------------|----------------|----------|
| Snake Sweeper (1 player) | ~50 | ~500 bytes | ~10 KB/s |
| Snake Sweeper (4 players) | ~80 | ~800 bytes | ~16 KB/s |
| TITAN demo (100+ entities) | ~130 | ~2 KB | ~40 KB/s |
| GENESIS (65 entities, 24 lights) | ~90 | ~1.2 KB | ~24 KB/s |

Well within WebSocket capabilities over any modern connection. A 3G mobile connection (1 Mbps) handles the heaviest scenario with 96% bandwidth to spare.

---

## 6. What Already Exists (v1.0 Foundation)

16 phases built and working. This is not a greenfield project — it's proven infrastructure ready for the network and intelligence layers.

| System | Status | Implementation |
|--------|--------|---------------|
| Window + Input | Done | winit 0.30, keyboard/mouse events |
| Scene Graph | Done | YAML scenes with entity/component definitions, inheritance |
| ECS | Done | hecs with Transform, MeshRenderer, Camera, Light, Hidden, EntityId |
| Deferred Rendering | Done | 8-stage pipeline: Shadow → G-Buffer → Splat → Lighting → Bloom → Tonemap → FXAA → UI |
| Gaussian Splatting | Done | .ply loader, custom splat renderer integrated into deferred pipeline |
| PBR Materials | Done | YAML material definitions, Cook-Torrance GGX, metallic/roughness/emissive |
| Shadow Mapping | Done | Directional shadow maps with PCF soft shadows |
| Post-Processing | Done | Bloom (HDR glow), tone mapping, FXAA anti-aliasing |
| Physics | Done | Rapier 3D: rigid bodies, colliders, joints, gravity |
| Scripting | Done | mlua (Lua 5.4): per-entity scripts, full API (entity, physics, audio, ui) |
| Audio | Done | Kira 0.9: music, SFX, fade-in/out, volume control, MP3/WAV/OGG |
| UI Overlay | Done | Immediate-mode 2D: text, rects, screen flash, 6x8 bitmap font atlas |
| Entity Commands | Done | Runtime spawn/destroy/scale/visibility from Lua scripts |
| MCP Server | Done | JSON-RPC over stdio, Claude can query/modify engine state |
| Telegram Bridge | Prototype | Bot receives commands, relays to engine via socket IPC |
| Event Bus | Done | Typed publish/subscribe for inter-system communication |
| Headless Mode | Done | `--headless` flag runs engine without window (for testing) |
| Shader Pipeline | Done | SLANG → WGSL compilation, YAML-defined render pipeline DAG |
| Procedural Meshes | Done | Sphere, cube, plane generated at runtime |

### Demo Scenes (16)

| Demo | Entities | Key Systems Exercised |
|------|----------|----------------------|
| Hello Cube | 3 | Basic rendering, camera |
| Material Test | 10 | PBR materials, lighting |
| Physics Demo | 20+ | Rapier rigid bodies, collision |
| Scripting Demo | 5 | Lua per-entity scripts |
| Splat Viewer | 1 | Gaussian splatting renderer |
| PBR Gallery | 25 | Metallic x roughness sweep |
| Neon Dreamscape | 30+ | Emissive materials, point lights |
| GENESIS | 65 | 24 lights, keyframe camera, Hermite interpolation |
| TITAN | 100+ | 32 lights, entity scaling, max complexity |
| INFERNO | 40+ | FPS arena, dynamic spawning |
| VOID | 10+ | Cosmic Gaussian splatting |
| Shadow Test | 15 | Directional shadow mapping |
| UI Demo | 20+ | Text, rects, colors, animations, screen flash |
| Grid UI Demo | 49+ | Runtime-spawned tiles, Minesweeper numbers |
| Audio Test | 10+ | Music, SFX triggers, UI feedback, MP3 playback |
| Event Bus Demo | 5 | Pub/sub inter-system communication |

---

## 7. Intelligence Layer

### 7.1 Natural Language Compiler

The fastest path to world creation. A user describes what they want; the system generates complete YAML + Lua files.

```
User:  "I want a 3D snake game on a neon grid with pulsing music"

NL Compiler:
  → scenes/snake.yaml           (scene graph: grid, snake, food, camera, lights)
  → logic/snake_controller.lua  (movement, growth, collision, scoring)
  → logic/food_spawner.lua      (random food placement, respawn)
  → materials/neon_grid.yaml    (emissive grid material)
  → materials/snake_body.yaml   (glowing green PBR material)
```

**Implementation path:** The MCP server already exists and Claude Code already knows the nAIVE format (it generated all 16 demo scenes). The NL Compiler is an MCP tool that:
1. Receives a natural language description
2. Calls Claude API with nAIVE format knowledge as system prompt
3. Claude generates scene YAML + Lua scripts + material definitions
4. Files are written to the project directory
5. Engine hot-reloads the scene

**Target:** >80% first-attempt correct scene generation (measured by: scene loads without error, entities are visible, basic interaction works).

### 7.2 LLM NPC Agents

Entities with `agent_brain` components become LLM-powered characters with persistent memory:

```yaml
- id: merchant
  components:
    transform:
      position: [5, 0, 3]
    mesh_renderer:
      mesh: assets/meshes/merchant.gltf
      material: assets/materials/merchant.yaml
    agent_brain:
      personality: "Gruff but fair dwarven blacksmith. Remembers repeat customers.
                    Gives discounts to regulars. Hates goblins."
      memory_slots: 50
      inference_tier: 2
```

**Agent architecture:** Perception (nearby entities, events) → Memory (vector store of past interactions) → Reasoning (LLM call with context) → Action (Lua function calls: move, speak, trade, emote).

**Tiered inference for cost control:**

| Tier | Latency | Cost/Call | Use Case | Implementation |
|------|---------|-----------|----------|---------------|
| 1 | 500ms | ~$0.01 | Complex conversation, novel situations | Claude API (Haiku for routine, Sonnet for complex) |
| 2 | 50ms | ~$0.001 | Routine dialogue, common questions | Distilled local model (Ollama / llama.cpp) |
| 3 | 1ms | ~$0 | Greetings, repeated queries, combat barks | Pattern match + template cache |

**Memory architecture:**
- Short-term: Last 10 interactions (full context)
- Long-term: Vector-indexed memory store (embed interactions, retrieve relevant ones)
- Personality: Immutable system prompt defining character traits
- Relationships: Per-player relationship score (affects dialogue tone, trade prices)

### 7.3 AI Director

A server-side background system that monitors player behavior telemetry and evolves the world in real-time:

```
Player Telemetry → Analysis → Intervention Plan → Graduated Response

Input signals:
  - Time between deaths
  - Score progression rate
  - Areas visited / avoided
  - Player idle time
  - Session duration
  - Mine hit rate (Snake Sweeper)

Intervention levels:
  Subtle:         Adjust spawn rates, lighting mood, music tempo, particle density
  Moderate:       Introduce new NPCs, modify terrain, create timed events
  Significant:    Restructure level layout, change game rules, add new mechanics
  Transformative: Genre shifts, narrative pivots (requires explicit player opt-in)
```

**For Snake Sweeper specifically:**
- If player hits 3+ mines in a row → reduce mine density by 20%, add extra food
- If player clears levels too easily → increase mine density, add obstacles
- If player stops moving (stuck) → flash a hint showing the nearest safe food path
- If player circumnavigates a mine → spawn a bonus item as positive reinforcement

The Director runs on the server. Its interventions become state deltas that all clients receive — everyone sees the world evolving.

**Fairness guardrail:** In multiplayer, the Director applies adjustments globally (affecting the shared world) or per-player only for UI hints. It never gives one player a mechanical advantage.

### 7.4 Generative Gaussian Splatting (Gen-3DGS)

Text descriptions → 3D Gaussian splat assets, bypassing the photogrammetry capture pipeline:

```
"obsidian cavern with bioluminescent fungi"
  → CLIP text encoding
  → Multi-view diffusion (Zero123++ / MVDream)
  → 3DGS reconstruction (rapid SfM-free pipeline)
  → Differentiable splat optimization
  → LOD generation (progressive pruning)
  → Integration: .ply asset registered in scene graph
```

**Quality tiers:**

| Tier | Gaussians | Generation Time | Use Case | Quality |
|------|-----------|----------------|----------|---------|
| Preview | ~10K | 2-5 seconds | Rapid iteration, placeholder | Draft |
| Standard | ~100K | 15-30 seconds | Gameplay assets | Good |
| High | ~500K | 1-3 minutes | Hero assets, key props | Excellent |
| Cinematic | ~2M | 5-15 minutes | Cutscenes, marketing | Photorealistic |

**Style transfer:** Generated splats can be style-transferred to match a target aesthetic. Provide a reference image or style description ("Studio Ghibli watercolor", "pixel art voxels", "dark souls gothic"), and the optimization phase guides spherical harmonic coefficients toward that visual style.

### 7.5 Neural Render Passes

Portions of the render pipeline replaced with differentiable, trainable neural networks:

```yaml
# render_pipeline.yaml extension
passes:
  - name: geometry_pass
    type: raster                  # traditional SLANG shader
    shader: geometry.slang
  - name: lighting_pass
    type: raster
    shader: deferred_light.slang
  - name: style_transfer
    type: neural                  # NEW in v4.0: learned weights
    weights: ghibli_style.neural_shader
    inputs: [color_buffer, depth_buffer]
    output: styled_color
  - name: super_resolution
    type: neural
    weights: 2x_upscale.neural_shader
    inputs: [styled_color]
    output: final_color
```

**Use cases:** Style transfer, ambient occlusion estimation, denoising, super-resolution — learned from data instead of hand-coded in SLANG.

**Training pipeline:** Reference rendering (path-traced) → Neural stage training (gradient descent) → Quantization (FP16/INT8) → Deployment as `.neural_shader` asset.

**Performance target:** >30 FPS on M1 MacBook with one neural pass active. Traditional SLANG shaders remain the default; neural passes are opt-in.

---

## 8. Telegram Integration

### 8.1 Architecture

```
┌──────────┐     ┌──────────────┐     ┌──────────────┐     ┌──────────────┐
│ Telegram  │────>│ nAIVE Bot    │────>│ AI Parser    │────>│ World Server │
│ User      │<────│ (teloxide)   │<────│ (Claude API) │<────│ (Lua exec)   │
└──────────┘     └──────────────┘     └──────────────┘     └──────────────┘
```

### 8.2 Command Flow

```
User on Telegram:
  "make it rain in black.squirrel.white.deer"

1. Bot receives message via Telegram Bot API
2. Bot extracts world reference: "black.squirrel.white.deer"
3. Bot sends NL command to AI parser: "make it rain"
4. AI parser (tiered):
   - Tier 3: Pattern match against common commands (hit rate ~60%)
   - Tier 1: Claude API call with world's available Lua functions as context
   - Returns: { "function": "weather.set", "args": ["rain"] }
5. Bot sends structured command to world server via internal API
6. Server looks up world by four-word name
7. Server executes in that world's Lua environment:
   weather.set("rain")
8. Lua script:
   - Spawns rain particle emitter entity
   - Shifts ambient light color (0.3, 0.3, 0.4) → darker, bluer
   - Plays rain audio loop at 0.4 volume with 3s fade-in
   - Modifies ground material roughness (dry → wet reflections)
9. State deltas broadcast to all connected clients
10. Every player sees rain appear
11. Bot replies to Telegram: "It's raining in black.squirrel.white.deer"
```

### 8.3 Bot Commands

```
/connect snake.3d.nokia.mark       — Subscribe to world events
/disconnect                        — Stop receiving updates
/status                            — World stats: players, entities, tick rate, uptime
/players                           — List connected players with their scores
/worlds                            — List your published worlds
/command <anything>                — Natural language command to the connected world

Examples:
  /command make it rain
  /command spawn 5 gold cubes at the center
  /command change the music to something spooky
  /command reset the game
  /command add a maze around the spawn point
  /command make the snake twice as fast for 30 seconds
  /command what's the highest score right now?
  /command pause the game
```

### 8.4 World Notifications (Push)

The bot also pushes events from the world to subscribed Telegram users:

```
"Player brave.fox.quick.nine achieved a high score of 12,450
 in snake.3d.nokia.mark (Level 8, Endless Mode)"

"New player joined black.squirrel.white.deer (3 players now connected)"

"ALERT: Chain reaction in snake.3d.nokia.mark — 4 mines detonated!"
```

Notification types are configurable per-subscription: all events, scores only, player joins only, etc.

---

## 9. First World: Snake Sweeper

Snake Sweeper is the first real game published on nAIVE v4.0. It proves every system end-to-end: ECS, scripting, physics, rendering, audio, UI, networking, Telegram control, and AI Director.

### 9.1 Why Snake Sweeper First

1. **Already designed.** A comprehensive 729-line game design document covers every mechanic, visual effect, scoring formula, and level structure (`docs/GAME_DESIGN_DOCUMENT.md`).
2. **Already prototyped.** The Grid UI demo (Phase 16) shows 49 runtime-spawned tiles, Minesweeper numbers as UI text, dynamic tile coloring, and an auto-walking snake.
3. **Audio proven.** testAssets MP3 files (eat.mp3, explosion.mp3, death.mp3, music.mp3) play correctly via Kira's symphonia decoder.
4. **Right scope.** Complex enough to stress every system (ECS, physics, scripting, UI, audio, entity spawning, fog-of-war shader), simple enough to build in weeks.
5. **Multiplayer natural fit.** Multiple snakes on the same minefield is immediately compelling — competitive mine avoidance.
6. **Telegram-controllable.** "add more mines", "change difficulty", "reset level", "make the snake faster" are obvious NL commands.
7. **AI Director showcase.** Adaptive difficulty based on mine hit rate is a perfect first Director implementation.

### 9.2 Network Architecture

```
Server (naive-server):
  ┌─────────────────────────────────────────────────┐
  │  Snake Sweeper World                            │
  │  ├── 17x17 Grid ECS (289 tile entities)        │
  │  ├── Mine system (hidden placement, fog)        │
  │  ├── Per-player snake entities (head + segments)│
  │  ├── Food spawner (4 + level items)             │
  │  ├── Scoring system (multipliers, combos)       │
  │  ├── AI Director (adaptive difficulty)          │
  │  └── State broadcaster (20 Hz deltas)           │
  └─────────────────────────────────────────────────┘

Client (naive-client):
  ┌─────────────────────────────────────────────────┐
  │  Local Renderer                                 │
  │  ├── 3D tile grid (PBR materials, fog shader)   │
  │  ├── Snake mesh (segments, head orientation)     │
  │  ├── Mine/food/obstacle meshes                  │
  │  ├── Explosion/sparkle particle effects          │
  │  ├── Heartbeat audio (proximity-based volume)    │
  │  ├── HUD: score, level, food icons, multiplier   │
  │  └── Input: WASD → server events                │
  └─────────────────────────────────────────────────┘

Telegram:
  "how's the game going?"  → Bot queries server for score, level, snake length
  "make it harder"         → Server increases mine density and snake speed
  "spawn a power-up"       → Server places a shrink power-up near the snake
  "show me the mines"      → Bot sends a text-art minimap of the board (spectator)
```

### 9.3 Core Mechanics Summary

| Mechanic | Description |
|----------|-------------|
| Growth-as-punishment | Mine hit → +3 segments (longer = harder to control) |
| Shrink-as-reward | Pass adjacent to mine → -1 segment |
| Proximity heartbeat | Procedural double-thump audio intensifies near mines |
| Mine circumnavigation | Visit all 8 surrounding tiles consecutively → defuse (highest-skill move, +100 x level x multiplier) |
| Number multipliers | Minesweeper numbers grant 2x-4x score multipliers for 5 seconds |
| Fog of war | Limited vision radius, shrinks 55% after mine hit for 5 seconds |
| Panic speed | 2x movement speed for 3.5s after mine hit (loss of control) |
| Chain reactions | Adjacent mines 50% chance to detonate on hit (cascading disaster) |
| 10-level campaign | Progressive difficulty → victory screen → endless mode |

Full design: `docs/GAME_DESIGN_DOCUMENT.md`

### 9.4 Second World: Relic v2.0 (Dungeon Crawler)

After Snake Sweeper proves the platform, Relic v2.0 is the second published world — a dungeon crawler showcasing every v4.0 AI capability:

- **Generative Dungeon:** Each session generates a unique dungeon via Gen-3DGS. Describe your ideal aesthetic before entering ("obsidian cavern with bioluminescent fungi" or "ancient Roman catacombs").
- **Conversational NPCs:** The merchant, quest-giver, and rival adventurer are all LLM agents with persistent memory. They remember previous runs, hold grudges, form alliances, and gossip about you to other NPCs.
- **Adaptive Challenge:** The AI Director monitors combat performance, exploration patterns, and puzzle-solving speed. It redesigns encounters mid-session — if you're breezing through combat, it introduces environmental puzzles; if you're stuck, it sends a helpful NPC with a cryptic hint.
- **Player Creation:** Between dungeon runs, players modify their home base using natural language ("add a trophy wall for my defeated bosses" or "build a garden with that crystal I found"). These modifications persist across sessions.
- **Shared Web Experience:** Relic runs entirely in the browser via WebGPU. Players share dungeon seeds and home bases via URL. A spectator mode lets friends watch live runs.
- **Style Modes:** Neural shader passes let players switch visual style mid-run — photorealistic, pixel art, ink wash painting, or comic book cel shading — without any asset changes.

---

## 10. Platform Targets and Distribution

nAIVE's technology stack (Rust + wgpu + winit) compiles natively to every major platform. The thin client architecture means the client binary is lightweight — it only needs rendering, audio, input, and WebSocket networking.

### 10.1 Build Targets

| Platform | GPU Backend | Window System | Audio | Build Toolchain | Status |
|----------|-----------|--------------|-------|----------------|--------|
| **macOS** (Intel + Apple Silicon) | Metal | winit (Cocoa) | Kira | `cargo build --target aarch64-apple-darwin` | DONE (primary dev platform) |
| **Windows** (x64) | Vulkan / DX12 | winit (Win32) | Kira | `cargo build --target x86_64-pc-windows-msvc` | Supported (wgpu) |
| **Linux** (x64) | Vulkan | winit (X11/Wayland) | Kira | `cargo build --target x86_64-unknown-linux-gnu` | Supported (wgpu) |
| **Browser** (WebGPU) | WebGPU | winit (Canvas) | Web Audio API | `wasm-pack build --target web` | Planned (Phase 3) |
| **Android** (ARM64) | Vulkan | winit (NativeActivity) | Oboe via Kira | `cargo ndk --target aarch64-linux-android` | Planned (Phase 4+) |
| **iOS** (ARM64) | Metal | winit (UIKit) | AVAudioEngine via Kira | `cargo build --target aarch64-apple-ios` | Planned (Phase 4+) |

### 10.2 Desktop Clients (macOS / Windows / Linux)

The native desktop client is the highest-fidelity experience:

```
naive-client connect black.squirrel.white.deer

  → Resolves four-word name to server address
  → WebSocket connection
  → Downloads scene + assets (cached in ~/.naive/cache/)
  → Full deferred PBR pipeline: Shadow → G-Buffer → Splat → Lighting → Bloom → Tonemap → FXAA
  → Neural render passes (if GPU supports compute shaders)
  → Kira audio: spatial, music, SFX
  → 60+ FPS on any dedicated GPU
```

**Distribution:**
- macOS: `.dmg` installer or Homebrew formula (`brew install naive-client`)
- Windows: `.msi` installer or `winget install naive-client`
- Linux: AppImage, Flatpak, or distro packages

**Why Rust makes this work:** A single `cargo build` produces native binaries for all three desktop OSes. wgpu abstracts Metal (macOS), Vulkan (Linux), and DX12/Vulkan (Windows). No cross-compilation pain, no runtime dependency on .NET/JVM/Electron.

### 10.3 Browser Client (WebGPU + WASM)

The zero-install path. wgpu compiles to WebGPU via wasm-bindgen + wasm-pack:

```
User receives link:  https://play.naive.world/black.squirrel.white.deer

  → Browser loads WASM client (<50 MB, cached after first load)
  → WebSocket connects to world server (native browser WebSocket)
  → Scene assets downloaded + cached (IndexedDB / Origin Private File System)
  → Renders locally via WebGPU
  → Plays audio via Web Audio API
  → Sends input via DOM events → WebSocket
  → First frame in <3 seconds on broadband
```

No download. No install. No app store. **Share a link, play a game.**

**Browser support:**
| Browser | WebGPU Status | Notes |
|---------|-------------|-------|
| Chrome 113+ | Shipped | Full support since April 2023 |
| Edge 113+ | Shipped | Chromium-based, same as Chrome |
| Firefox 121+ | Shipped (Nightly → Stable) | Full support |
| Safari 18+ | Shipped | macOS + iOS |
| Chrome Android | Shipped | Mobile WebGPU |
| Safari iOS | Shipped (18+) | Metal backend via WebGPU |

**Fallback:** For browsers without WebGPU, a WebGL2 fallback renderer provides reduced-feature rendering (no compute shaders, no neural passes, simplified lighting).

### 10.4 Mobile Clients (Android / iOS)

The thin client model makes mobile viable — the server runs all game logic, so the mobile client only needs to render and capture touch input.

**Android:**
```
Build: cargo ndk --target aarch64-linux-android --platform 28
GPU:   Vulkan 1.0 (97% of Android devices with Android 9+)
Audio: Oboe (low-latency Android audio, Kira backend)
Input: Touch events → map to directional input → send to server
Dist:  Google Play Store APK / F-Droid
Size:  ~30 MB APK (Rust binary + bundled assets)
```

**iOS:**
```
Build: cargo build --target aarch64-apple-ios
GPU:   Metal (all iOS devices since iPhone 6s / A9)
Audio: AVAudioEngine (Kira backend)
Input: Touch events → map to directional input → send to server
Dist:  TestFlight → App Store
Size:  ~25 MB IPA
```

**Mobile-specific considerations:**
- **Touch input mapping:** Virtual D-pad overlay for Snake Sweeper, swipe gestures for navigation
- **Battery:** Target 3+ hours continuous play. Reduce tick rate to 10 Hz, cap frame rate to 30 FPS in battery-saver mode
- **Network:** Mobile connections are higher-latency (50-200ms). Snake Sweeper's 280ms tick accommodates this. Client-side input prediction smooths visual lag.
- **Screen size:** UI overlay scales to screen density. Minimum supported: 5" 720p

### 10.5 Platform Equivalence Matrix

| Feature | Desktop (Native) | Browser (WASM) | Android | iOS |
|---------|-----------------|----------------|---------|-----|
| Rendering | wgpu (Vulkan/Metal/DX12) | WebGPU | wgpu (Vulkan) | wgpu (Metal) |
| Compute | Native GPU | WebGPU Compute | Vulkan Compute | Metal Compute |
| Audio | Kira (cpal) | Web Audio API | Kira (Oboe) | Kira (AVAudio) |
| Networking | WebSocket (tokio) | WebSocket (browser) | WebSocket (tokio) | WebSocket (tokio) |
| Storage | ~/.naive/cache | IndexedDB | App internal storage | App container |
| Neural passes | Full support | WebGPU compute | Vulkan compute | Metal compute |
| Gaussian splats | Full support | Full support | Full support (perf-limited) | Full support |
| Install required | Yes (binary) | No (URL) | Yes (APK) | Yes (IPA) |

### 10.6 Sharing and Discovery

- **Publish:** `naive publish snake.3d.nokia.mark` — uploads world files to server
- **Play (browser):** `https://play.naive.world/snake.3d.nokia.mark` — instant browser play
- **Play (native):** `naive-client connect snake.3d.nokia.mark` — native window
- **Play (mobile):** Open nAIVE app → enter four words → play
- **Browse:** `https://naive.world/explore` — searchable directory of public worlds
- **Fork:** Clone any public world to remix under a new four-word name
- **Version control:** World state snapshots, rollback to any point, branch for experiments
- **Permissions:** Public (anyone can join), private (owner only), invite-only (allowlist of player IDs)
- **Deep links:** `naive://connect/black.squirrel.white.deer` — opens native/mobile app directly

---

## 11. Multi-Agent Collaborative Development

### 11.1 Agent Swarm

Multiple specialized AI agents collaborate to build, test, and evolve worlds:

| Agent | Responsibility | Tools / Access |
|-------|---------------|---------------|
| Level Architect | Spatial layouts, terrain generation, landmarks | NL Compiler, Gen-3DGS, Scene YAML |
| Narrative Director | Quests, dialogue trees, NPC personalities, story arcs | Character YAML, Lua scripts, NPC agents |
| Systems Designer | Game mechanics, economy rules, balance tuning | Component definitions, Lua, balance data |
| QA Tester | Plays autonomously, finds bugs, reports edge cases | Full game API, telemetry, bug tracker |
| Art Director | Visual consistency, style guidance, material review | Neural shaders, Gen-3DGS, materials YAML |
| Orchestrator | Coordinates other agents, resolves conflicts, manages priorities | All APIs, project state, user preferences |

### 11.2 Collaboration Protocol

1. An agent proposes a change (e.g., "Add a hidden cave behind the waterfall with a treasure chest")
2. Affected agents review: Level Architect checks spatial fit, Systems Designer checks economy impact, Art Director checks visual consistency
3. Conflicts are resolved by the Orchestrator, which can escalate to the human designer
4. Approved changes are atomically committed to the scene graph
5. QA Tester plays through affected areas and reports regressions

### 11.3 Human-in-the-Loop

The agent swarm presents proposals. The human designer accepts, modifies, or rejects. The system learns from these decisions to better anticipate preferences. **The human remains the creative authority — AI amplifies, never overrides.**

---

## 12. World Registry and Naming

### 12.1 Registry Architecture

```
┌─────────────────────────────────────────────────┐
│  World Registry Service                         │
│                                                 │
│  Storage: SQLite (single-file, portable)        │
│                                                 │
│  Tables:                                        │
│    worlds:                                      │
│      id         UUID PRIMARY KEY                │
│      name       TEXT UNIQUE (four-word address)  │
│      owner      TEXT                            │
│      server     TEXT (server hostname)           │
│      created    TIMESTAMP                       │
│      status     ENUM (active, paused, archived) │
│      config     JSON (max_players, tick_rate)    │
│                                                 │
│    dictionary:                                  │
│      word       TEXT PRIMARY KEY                │
│      category   TEXT (noun, adjective)           │
│      syllables  INTEGER                         │
│                                                 │
│  API:                                           │
│    GET  /resolve/{word1}.{word2}.{word3}.{word4} │
│    POST /register  { name, server, owner }       │
│    GET  /browse    { category, sort, page }      │
│    POST /publish   { name, assets[] }            │
│    GET  /health/{world_id}                       │
│                                                 │
└─────────────────────────────────────────────────┘
```

### 12.2 Name Generation

When a creator publishes a world without specifying a name, the system generates one:

```
1. Draw 4 words randomly from dictionary (uniform distribution)
2. Check uniqueness against registry
3. If collision (astronomically unlikely), redraw
4. Present to creator: "Your world address is: golden.tiger.swift.rain"
5. Creator can accept or request a new random name
```

Creators can also request specific names (first-come, first-served). Reserved names: none. The namespace is large enough that squatting is impractical.

### 12.3 Multiplayer and Player Identity

- **Anonymous by default:** First connection gets a randomly generated four-word player name (`brave.fox.quick.nine`)
- **Telegram identity:** If connected via Telegram, uses Telegram username
- **Persistent identity:** Optional account creation (email or Telegram link) to maintain consistent player name and stats across sessions
- **Permissions per world:** Owner (full control), Editor (can modify via NL), Player (can play), Viewer (spectate only)

---

## 13. Implementation Status and Roadmap

### 13.0 Feature Implementation Status

Every capability in this PRD is categorized by implementation status:

| Feature | Status | PRD Origin | Notes |
|---------|--------|-----------|-------|
| **v1.0 Core Engine** | | | |
| wgpu deferred rendering pipeline | DONE | v1.0 | 8-stage pipeline, Phases 1-14 |
| hecs ECS with Transform, Camera, Light | DONE | v1.0 | Full component set |
| SLANG → WGSL shader compilation | DONE | v1.0 | Cross-compilation at load time |
| YAML scene graph + data-driven pipeline | DONE | v1.0 | Scenes, materials, render pipeline |
| Rapier 3D physics | DONE | v1.0 | Rigid bodies, colliders, joints |
| Lua scripting (mlua 5.4) | DONE | v1.0 | Per-entity scripts, full API |
| Kira audio (music, SFX, spatial) | DONE | v1.0 | MP3/WAV, fade, volume control |
| Gaussian splatting renderer (.ply) | DONE | v1.0 | First-class primitive in G-Buffer |
| PBR materials (Cook-Torrance GGX) | DONE | v1.0 | Metallic/roughness/emissive |
| Shadow mapping (directional, PCF) | DONE | v1.0 | Phase 14 |
| Bloom + tone mapping + FXAA | DONE | v1.0 | Phase 14-15 |
| Immediate-mode UI overlay | DONE | v1.0 | Phase 16: text, rects, flash |
| Bitmap font atlas (6x8 pixel) | DONE | v1.0 | Phase 16: 95 ASCII glyphs |
| Entity spawn/destroy from Lua | DONE | v1.0 | Phase 16: EntityCommandQueue |
| Entity visibility (Hidden component) | DONE | v1.0 | Phase 16 |
| MCP server (JSON-RPC) | DONE | v1.0 | Claude integration |
| Event bus (typed pub/sub) | DONE | v1.0 | Inter-system communication |
| Headless mode (--headless) | DONE | v1.0 | No window, for testing |
| Procedural meshes (sphere, cube, plane) | DONE | v1.0 | Runtime generation |
| **v1.0 Demos** | | | |
| 16 demo scenes | DONE | v1.0 | All working, documented in demos.html |
| Audio test (testAssets MP3) | DONE | v1.0 | Phase 16, Kira + symphonia |
| Grid UI demo (Snake Sweeper proto) | DONE | v1.0 | Phase 16, 49 tiles + numbers |
| **v2.0 Intelligence Layer** | | | |
| Natural Language Compiler (text → YAML) | PLANNED | v2.0 | Phase 3, weeks 9-10 |
| LLM NPC agents (agent_brain component) | PLANNED | v2.0 | Phase 3, weeks 11-12 |
| AI Director (adaptive difficulty) | PLANNED | v2.0 | Phase 3, weeks 13-14 |
| Gen-3DGS (text → Gaussian splats) | PLANNED | v2.0 | Phase 4, weeks 17-20 |
| Neural render passes (learnable shaders) | PLANNED | v2.0 | Phase 4, weeks 21-24 |
| Dynamic plugin system (hot-load .dylib) | PLANNED | v2.0 | Phase 4 |
| Self-modifying engine | PLANNED | v2.0 | Phase 4, depends on plugin system |
| Multi-agent collaborative dev (swarm) | PLANNED | v2.0 | Phase 4, weeks 25-28 |
| Extended MCP tools (14 endpoints) | PLANNED | v2.0/v4.0 | Incremental, per-feature |
| New ECS components (see below) | PLANNED | v2.0 | Added per-feature |
| **v3.0 Network Layer** | | | |
| Headless server binary (naive-server) | PLANNED | v3.0 | Phase 1, week 3 |
| WebSocket state streaming | PLANNED | v3.0 | Phase 1, week 4 |
| Thin client binary (naive-client) | PLANNED | v3.0 | Phase 2, week 5 |
| Four-word world registry | PLANNED | v3.0 | Phase 2, week 6 |
| Multiplayer (multi-player per world) | PLANNED | v3.0 | Phase 2, week 7 |
| Telegram bridge v2 (AI-parsed NL) | PLANNED | v3.0 | Phase 2, week 8 |
| Telegram bridge v1 (basic relay) | PROTOTYPE | v1.0 | GENESIS demo, socket IPC |
| **v4.0 Platform** | | | |
| WebGPU/WASM browser client | PLANNED | v2.0/v4.0 | Phase 3, weeks 15-16 |
| World browser (naive.world) | PLANNED | v4.0 | Phase 4, weeks 29-32 |
| World forking + permissions | PLANNED | v4.0 | Phase 4 |
| Asset CDN | PLANNED | v4.0 | Phase 4 |
| Relic v2.0 demo game | PLANNED | v2.0 | After Snake Sweeper |

**Summary:** 20 features DONE (v1.0 complete), 2 PROTOTYPE, 20+ PLANNED across phases 1-4.

### 13.0.1 New ECS Components (v4.0)

All v1.0 components remain. v4.0 adds:

| Component | Purpose | Depends On |
|-----------|---------|-----------|
| `agent_brain` | Attaches LLM agent to entity: personality, memory, inference tier | NPC Agent system |
| `director_target` | Marks entity as subject to AI Director intervention, with level cap | AI Director |
| `generated_asset` | Tracks provenance of AI-generated assets: prompt, quality tier, timestamp | Gen-3DGS |
| `nl_editable` | Marks entity as modifiable via natural language commands in play mode | NL Compiler |
| `network_replicated` | Marks entity for state delta replication to connected clients | Network layer |
| `player_owned` | Associates entity with a specific player session | Multiplayer |

### Phase 1 — Immediate (Weeks 1-4): Snake Sweeper + Headless Server

**Goal:** Snake Sweeper playable locally as a complete game. Headless server binary compiles and runs the same world without GPU.

| Week | Deliverable |
|------|------------|
| 1 | Snake Sweeper core: 17x17 grid, mine placement, food spawning, fog-of-war, snake movement, collision detection, scoring system |
| 2 | Snake Sweeper polish: explosion/sparkle/implosion particle effects, proximity heartbeat audio, mine circumnavigation, screen shake, HUD (score, level, food icons, multiplier), splash/game-over/victory screens |
| 3 | Headless server binary: feature-flagged Cargo build excluding wgpu/winit/kira, `naive-server` compiles and runs Snake Sweeper ECS + Lua headlessly |
| 4 | WebSocket state streaming: server broadcasts state deltas, second `naive-runtime` instance connects and renders the same world state |

**Exit criteria:**
- Snake Sweeper runs as a complete 10-level + endless mode game with all GDD mechanics
- `cargo build --bin naive-server --features server` produces a working headless binary
- Two `naive-runtime` instances show the same world state via WebSocket

### Phase 2 — Near-Term (Weeks 5-8): Thin Client + Four-Word Names + Telegram

| Week | Deliverable |
|------|------------|
| 5 | Thin client binary: `naive-client connect <address>` receives scene + deltas, renders locally |
| 6 | Four-word world registry: SQLite-backed name resolution, `naive publish` command, REST API |
| 7 | Multiplayer Snake Sweeper: 2-4 player snakes on shared minefield, per-player scoring, collision between snakes |
| 8 | Telegram bridge v2: AI-parsed NL commands to live worlds, world notifications |

**Exit criteria:**
- `naive-client connect snake.3d.nokia.mark` opens a window rendering the live game
- Two players play Snake Sweeper simultaneously on the same board
- Telegram message "/command make it harder" increases mine density in real-time

### Phase 3 — Medium-Term (Weeks 9-16): Intelligence Layer + Browser

| Weeks | Deliverable |
|-------|------------|
| 9-10 | NL Compiler v1: text → YAML + Lua scene generation via Claude API MCP tool |
| 11-12 | NPC Agent prototype: single LLM entity with Tier 1-3 inference, memory, personality |
| 13-14 | AI Director v1: player telemetry → adaptive difficulty for Snake Sweeper |
| 15-16 | WebGPU/WASM build: `naive-client` compiles to browser, plays at `play.naive.world` |

**Exit criteria:**
- "I want a 3D snake game" produces a playable scene on first attempt (>80%)
- An NPC merchant in a demo world remembers conversations across sessions
- Snake Sweeper adapts difficulty based on player mine-hit rate
- Snake Sweeper plays in Chrome/Firefox via WebGPU with no native install

### Phase 4 — Long-Term (Weeks 17-32): Advanced AI + Platform

| Weeks | Deliverable |
|-------|------------|
| 17-20 | Gen-3DGS pipeline: text description → Gaussian splat .ply assets (Preview tier) |
| 21-24 | Neural shader prototype: single learnable post-processing pass (style transfer) |
| 25-28 | Multi-agent collaboration: 3+ agent swarm builds a world from a brief |
| 29-32 | Web platform: world browser at naive.world, forking, permissions, CDN, ratings |

---

## 14. Technical Specifications

### 14.1 Server Requirements

| Resource | Per World | 100 Worlds |
|----------|----------|-----------|
| CPU | 2 cores (ECS tick + Lua + physics) | 8-16 cores (worlds share via tokio) |
| Memory | ~50 MB (ECS + physics + scripts) | ~5 GB |
| Network (egress) | ~10 KB/s per client | ~100 KB/s (assuming 10 avg clients) |
| Disk | ~10 MB (scene + assets) | ~1 GB |
| **Cost estimate** | — | **$20-40/month VPS** |

A single modest VPS (4 vCPU, 8 GB RAM, $20/month) handles ~100 concurrent worlds with 1-10 clients each.

### 14.2 Client Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| GPU | Intel UHD 620 / Apple M1 | Any dedicated GPU / M1 Pro+ |
| VRAM | 512 MB | 2 GB+ |
| RAM | 512 MB | 2 GB |
| Network | 100 Kbps (sufficient for deltas) | 1 Mbps (fast asset download) |
| Browser | Chrome 113 / Firefox 121 / Safari 18 | Latest stable |

### 14.3 Latency Budget

```
Snake Sweeper game tick: 280ms (snake moves one tile every 0.28s)

Input event → server:     20-50ms  (client → WebSocket → server)
Server tick processing:   1-5ms    (Lua + ECS + physics)
State delta → client:     20-50ms  (server → WebSocket → client)
Client render:            <16ms    (60 FPS local)

Total round-trip:         ~60-120ms

Budget remaining:         160-220ms (plenty of slack for Snake Sweeper's pace)
```

For reference, competitive FPS games need <20ms round-trip at 128Hz tick. Snake Sweeper's 280ms tick is 14x more forgiving.

---

## 15. Risk Assessment

| Risk | Severity | Mitigation | Fallback |
|------|----------|-----------|----------|
| WebSocket latency for gameplay | Low | Snake Sweeper's 280ms tick provides 200ms+ slack. Client-side input prediction for visual responsiveness. | Increase tick rate for faster games; evaluate WebRTC DataChannels for v5.0 |
| LLM API cost at scale (NPCs) | High | Tiered inference: Tier 3 cache handles 60%+ of interactions at zero cost. Tier 2 local models for routine. Tier 1 API only for complex/novel. | Sophisticated behavior trees with LLM-generated dialogue cache |
| WebGPU browser adoption gaps | Medium | wgpu abstracts backends. WebGL2 fallback renderer with reduced features. | Native-first distribution; browser as progressive enhancement |
| Gen-3DGS quality insufficient | Medium | Progressive quality tiers. Offline generation for high quality. | Curated splat asset library with style transfer |
| Server scaling beyond 100 worlds | Medium | Lightweight worlds (~50MB each). Horizontal scaling via world migration between servers. | Peer-to-peer mode for simple worlds (client holds state) |
| Telegram bot rate limits | Low | Queue commands, batch updates, 1 command/second per user | Direct WebSocket API as alternative control channel |
| Neural shader perf on consumer GPU | High | FP16/INT8 quantization, resolution scaling, optional | Traditional SLANG shaders as default; neural passes are opt-in |
| Four-word name squatting | Low | 16 trillion address space makes squatting impractical. Inactive worlds archived after 90 days. | Hierarchical names: `mark.snake.3d.nokia` (owner prefix) |
| Asset piracy (world cloning) | Low | Public worlds are intentionally forkable (it's a feature). Private worlds require auth. | Watermarking generated assets; DMCA takedown process |

---

## 16. Success Metrics

### 16.1 Technical Metrics

| Metric | Target | How Measured |
|--------|--------|-------------|
| Server tick rate | 20 Hz sustained with 4 players | Tick time profiling (p95 < 50ms) |
| State delta latency | <100ms server→client | WebSocket round-trip timestamps |
| Client frame rate | >60 FPS on M1 MacBook | Automated benchmark scene |
| WASM binary size | <50 MB initial load | Build output measurement |
| World startup time | <3s from connect to first frame | Client-side timing (broadband) |
| NL Compiler accuracy | >80% first-attempt correct scenes | Human evaluation panel |
| NPC response (Tier 1) | <500ms | P95 response time logging |
| NPC response (Tier 3) | <5ms | P95 cache lookup timing |
| Gen-3DGS preview | <5s for 10K Gaussians | End-to-end pipeline timing |
| Neural shader FPS | >30 FPS on M1 with one neural pass | Automated benchmark |
| Concurrent worlds/server | 100+ on 4-vCPU VPS | Load testing |

### 16.2 Experience Metrics

- A non-programmer creates a playable game world in <5 minutes using only natural language
- Snake Sweeper is playable by 4 concurrent players with no perceptible desync
- A Telegram "/command" changes the live world within 1 second (visible to all clients)
- Sharing a four-word address is the **only** step needed for someone to join a world
- Browser client is visually indistinguishable from native client for Snake Sweeper complexity
- New players understand the four-word system without explanation ("connect to golden.tiger.swift.rain")
- NPC conversations feel meaningfully different across multiple sessions (memory validated)
- AI Director interventions are rated "helpful" or "invisible" by >70% of playtesters

---

## 17. Comparison to Existing Platforms

| Feature | nAIVE v4.0 | Roblox | Unity | Unreal | Minecraft |
|---------|-----------|--------|-------|--------|-----------|
| World creation | Natural language | Lua + Studio | C# + Editor | C++ + Blueprints | Manual blocks |
| Distribution | 4-word address | Roblox app | App stores | App stores | Server IP |
| Browser play | WebGPU (zero install) | No | No (unless WebGL) | Pixel streaming | No |
| AI NPCs | LLM agents (Tier 1-3) | Scripted | Scripted | Scripted/MetaHuman | Scripted |
| AI Director | Built-in, adaptive | No | Manual | No | No |
| External control | Telegram, MCP, CLI | No | No | No | RCON (limited) |
| World format | YAML + Lua (human-readable) | Proprietary | Proprietary scenes | Proprietary | NBT (binary) |
| Gaussian splatting | Native, generative | No | Plugin | Plugin (Luma) | No |
| Server cost | $0.20/world/month | Roblox-hosted | Self-hosted | Self-hosted | Self-hosted |
| Open source | Yes (Rust, MIT) | No | No | Source available | No |

---

## 18. Evolution from Prior PRDs

### 18.1 What v4.0 Adds Beyond v1.0 + v2.0 + v3.0

| Topic | Prior PRDs | v4.0 Resolution |
|-------|-----------|-----------------|
| Rendering location | v3.0 stated "client-side" without analysis | Full three-option evaluation with cost modeling (Section 3.1) |
| Four-word addressing | v3.0 proposed the concept | Formal specification: dictionary rules, math, prior art, registry API (Sections 3.2, 11) |
| Why not UDP | Unstated | Explicit WebSocket justification with latency budget analysis (Section 3.4) |
| Why Lua server-only | Unstated | Security and consistency rationale (Section 3.5) |
| Telegram flow | v3.0 outlined concept | Complete architecture: bot → AI parser → server → Lua → delta → clients (Section 7) |
| Snake Sweeper as first world | Mentioned in v3.0 | Full network architecture, GDD integration, AI Director integration (Section 8) |
| Player identity | v3.0 mentioned "four-word player names" | Formal identity model: anonymous → Telegram → persistent account (Section 11.3) |
| Cost analysis | Not included | Server cost modeling: $20-40/month for 100 worlds (Sections 3.1, 13.1) |
| Latency budget | Not included | Full round-trip analysis against Snake Sweeper's 280ms tick (Section 13.3) |
| Platform comparison | Not included | Feature matrix vs Roblox, Unity, Unreal, Minecraft (Section 16) |
| Unified roadmap | v2.0 and v3.0 had separate timelines | Single 32-week phased roadmap integrating all layers (Section 13) |
| SLANG as differentiator | Mentioned but not explained | Full rationale: cross-compilation, modularity, differentiability for neural shaders (Section 3.1) |
| Gaussian splatting as primitive | Listed as a feature | Elevated to core differentiator with mixed mesh/splat scene examples (Section 3.2) |
| Data-driven YAML pipeline | Unstated | Full pipeline YAML specification with neural pass integration (Section 3.3) |
| AI as runtime primitive | Implied in v2.0 | Explicit positioning: AI is an engine system, not a dev tool (Section 3.4) |
| Plugin system | Defined in v2.0 | Integrated with full NaivePlugin trait and hot-swap use cases (Section 3.5) |
| Extended MCP tools | Defined in v2.0 | 14-endpoint specification covering all v4.0 capabilities (Section 3.6) |
| Cross-platform build targets | Browser only in v2.0 | Full matrix: macOS, Windows, Linux, Browser, Android, iOS (Section 10) |
| Implementation status tracking | Not included | Complete feature matrix with DONE/PROTOTYPE/PLANNED status (Section 13.0) |
| New ECS components | Listed in v2.0 | Integrated with dependencies and purpose (Section 13.0.1) |
| Relic v2.0 demo game | Described in v2.0 | Integrated as second world after Snake Sweeper (Section 9.4) |
| v1.0 design philosophy | Stated as principles in v1.0 Executive Summary | Formalized as Section 2.3: "AI agent IS the editor", "Everything is a file", "Unix pipes connect everything", "AI observability built in", "SLANG from day one", "Gaussian splats as first-class primitive" |
| Rendering revolution vision | v1.0 implied via tech choices; v2.0 described neural shaders and Gen-3DGS | Full rendering manifesto in Section 2.4: trajectory from rasterization → PBR → splats → neural rendering → prompt-to-render, AI asset generation via pipes (Meshy, ElevenLabs, Flux), closed-loop AI observability, visual style as swappable data |
| AI asset generation services | v1.0 mentioned "Meshy for 3D, ElevenLabs for audio, Flux for textures" | Integrated into design philosophy (Section 2.3) and rendering vision (Section 2.4) as external AI services via Unix pipes |
| Prompt-to-render endgame | Implied but never stated | Section 2.4 defines the full pipeline: natural language → geometry (Gen-3DGS) + lighting + particles + atmosphere + style (neural pass) + audio — all from a single sentence |

### 18.2 Version History

| Version | Date | Focus | Status |
|---------|------|-------|--------|
| v1.0 | Jan 2026 | Core engine specification: 20-week plan, Rust + wgpu + SLANG + hecs + Lua + YAML | Complete (16 phases shipped) |
| v2.0 | Feb 2026 | AI runtime layer: LLM NPCs, NL compiler, AI Director, Gen-3DGS, neural shaders, web platform | Specification complete, subsumed into v4.0 |
| v3.0 | Feb 2026 | Network layer: server authority, four-word addresses, thin client, Telegram bridge | Specification complete, subsumed into v4.0 |
| **v4.0** | **Feb 2026** | **Unified platform PRD: all layers integrated, rendering revolution vision (prompt-to-render, neural shaders, AI-generated geometry), v1.0 design philosophy formalized, cross-platform targets (Desktop/Mobile/Browser), architectural decisions resolved, SLANG/3DGS/neural rendering as core differentiators, implementation status tracked, Snake Sweeper + Relic as proof-of-concept worlds** | **Current document** |

---

## Appendix A: Existing Codebase Map

```
src/
  main.rs            — Entry point, module declarations
  engine.rs          — Core engine loop, system orchestration (~1200 lines)
  renderer.rs        — Forward renderer (legacy, unused in deferred mode)
  pipeline.rs        — Deferred render pipeline: Shadow → G-Buffer → Splat → Lighting → Bloom → Tonemap → FXAA
  shader.rs          — SLANG → WGSL compilation, shader module cache
  world.rs           — Scene loading, ECS setup, entity lifecycle, EntityCommandQueue
  components.rs      — ECS components: Transform, MeshRenderer, Camera, Light, Hidden, EntityId, etc.
  scripting.rs       — Lua runtime: entity/physics/audio/ui/input API registration
  physics.rs         — Rapier 3D: rigid bodies, colliders, joints, gravity
  audio.rs           — Kira 0.9: music, SFX, spatial volume, fade-in/out
  ui.rs              — Immediate-mode 2D overlay: text, rects, screen flash (~475 lines)
  font.rs            — Bitmap font atlas: 6x8 pixel, 95 ASCII glyphs (~370 lines)
  event_bus.rs       — Typed pub/sub event system
  mcp_server.rs      — MCP JSON-RPC server for Claude integration
  cli.rs             — CLI argument parsing: --scene, --headless, --project
  splat.rs           — Gaussian splatting renderer (.ply loader + render pass)
  material.rs        — PBR material loading from YAML
  mesh.rs            — glTF mesh loading + procedural mesh generation (sphere, cube, plane)

project/
  scenes/            — 16 YAML scene definitions
  logic/             — Lua game scripts (per-entity behavior)
  assets/
    materials/       — PBR material YAML files (metallic, roughness, emissive, etc.)
    meshes/          — glTF 3D models
    splats/          — Gaussian splatting .ply files
  shaders/
    passes/          — SLANG shader source (geometry, lighting, bloom, tonemap, fxaa)
    modules/         — Shared SLANG modules (PBR, shadows, common)

testAssets/          — Audio test files: eat.mp3, explosion.mp3, death.mp3, music.mp3

docs/
  nAIVE_Engine_PRD_v1.0.pdf      — Original engine specification (20-week plan)
  nAIVE_Engine_PRD_v2.0.pdf      — AI runtime layer specification (64-week roadmap)
  nAIVEv3.md                     — Networked worlds architecture notes
  nAIVE_Engine_PRD_v3.0.md       — Previous unified spec (superseded by v4.0)
  nAIVE_Engine_PRD_v4.0.md       — This document (unified platform specification)
  GAME_DESIGN_DOCUMENT.md        — Snake Sweeper complete game design (729 lines)
  SNAKE_SWEEPER_DEV_LOG.md       — Snake Sweeper development log
  architecture.html              — Interactive architecture diagram
  demos.html                     — Demo scene gallery with run commands
```

## Appendix B: Four-Word Dictionary Sample

Representative sample from the ~2,000 word curated dictionary:

**Adjectives (500 words):** `amber`, `ancient`, `black`, `blue`, `bold`, `brave`, `bright`, `bronze`, `calm`, `cold`, `coral`, `crimson`, `crystal`, `dark`, `deep`, `emerald`, `faint`, `fierce`, `frozen`, `gentle`, `glass`, `golden`, `grand`, `green`, `hidden`, `hollow`, `iron`, `jade`, `keen`, `light`, `long`, `marble`, `midnight`, `noble`, `pale`, `phantom`, `quiet`, `rapid`, `red`, `royal`, `ruby`, `rustic`, `scarlet`, `shadow`, `sharp`, `silent`, `silver`, `slate`, `soft`, `solar`, `stark`, `steel`, `storm`, `subtle`, `swift`, `thorn`, `thunder`, `twilight`, `vast`, `velvet`, `violet`, `vivid`, `warm`, `white`, `wild`, `winter` ...

**Nouns (1,500 words):** `arch`, `arrow`, `aurora`, `badger`, `bell`, `blade`, `bloom`, `bridge`, `brook`, `candle`, `canyon`, `castle`, `cedar`, `cliff`, `cloud`, `cobra`, `comet`, `crane`, `creek`, `crown`, `crystal`, `dagger`, `dawn`, `deer`, `delta`, `desert`, `dove`, `dragon`, `drift`, `drum`, `dusk`, `eagle`, `echo`, `ember`, `falcon`, `fern`, `flame`, `flint`, `fog`, `forest`, `forge`, `fox`, `frost`, `gate`, `glacier`, `grove`, `gull`, `harbor`, `hawk`, `heart`, `heron`, `hill`, `horn`, `horse`, `island`, `ivy`, `jade`, `lake`, `lark`, `leaf`, `light`, `lily`, `lion`, `lotus`, `lynx`, `maple`, `marsh`, `mesa`, `mist`, `moon`, `moss`, `moth`, `oak`, `ocean`, `orchid`, `osprey`, `otter`, `owl`, `palm`, `panther`, `peak`, `pearl`, `pine`, `plume`, `pond`, `quail`, `rain`, `raven`, `reef`, `ridge`, `river`, `robin`, `sage`, `seal`, `seed`, `shade`, `shell`, `shore`, `snow`, `spark`, `spider`, `spring`, `squirrel`, `star`, `stone`, `stream`, `summit`, `swan`, `thorn`, `thrush`, `thunder`, `tide`, `tiger`, `trail`, `trout`, `vale`, `vine`, `violet`, `viper`, `wave`, `whale`, `willow`, `wind`, `wolf`, `wren` ...

**Pattern:** `{adjective}.{noun}.{adjective}.{noun}` (preferred) or any combination of 4 dictionary words.

## Appendix C: Snake Sweeper Scoring Reference

| Event | Points | Notes |
|-------|--------|-------|
| Food eaten | +10 x level x multiplier | Primary progression |
| Mine avoided (shrink) | +25 x level x multiplier | Skill reward |
| Mine circumnavigated (defuse) | +100 x level x multiplier | Highest skill move |
| Number "1" tile bonus | +15 x level x multiplier | Exploration reward |
| Number 2/3/4 tile | Activates Nx multiplier (5s) | Risk/reward in dense mine areas |
| Mine hit (penalty) | -15 x level | No multiplier applied |
| Chain detonation (penalty) | -10 x level per chain | Cascading punishment |
| Level complete (bonus) | +50 x level | Milestone reward |

## Appendix D: Glossary

| Term | Definition |
|------|-----------|
| **Four-word address** | A human-memorable world identifier: `black.squirrel.white.deer` |
| **State delta** | A compact update message containing only changed entity components |
| **Thin client** | A rendering-only client that receives state from the server |
| **Server authority** | Architecture where the server computes all game state; clients only render |
| **Tick rate** | How many times per second the server updates world state (10-30 Hz) |
| **AI Director** | Server-side system that monitors player behavior and adapts the world |
| **Gen-3DGS** | Generative Gaussian Splatting: text → 3D Gaussian splat assets |
| **Neural pass** | A render pipeline stage implemented as a trained neural network |
| **NL Compiler** | Natural Language Compiler: converts text descriptions to YAML + Lua scenes |
| **World** | A complete interactive 3D environment: scene YAML + Lua scripts + assets |
| **MCP** | Model Context Protocol: JSON-RPC interface for Claude to interact with the engine |

---

*"The most interesting games of the next decade will not be authored — they will be grown, evolved, inhabited, and co-created by humans and AI working together in shared persistent worlds."*

— End of Document —
